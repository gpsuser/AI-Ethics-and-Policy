# AI Integration and Experimentation Policy

## Promotion of Experimentation
   - Employees are encouraged to experiment with AI technologies, especially LLMs like ChatGPT, within the guidelines of our policies.
   - Organizational leaders are urged to promote a culture of innovation and openness, emphasizing the importance of calculated risk-taking in AI experimentation.
   - Feedback mechanisms should be established where employees can voice their experiences, challenges, and successes in AI experimentation.
   - We advocate for continued education and training in AI technologies. We encourage employees to further their knowledge through relevant online courses, workshops, or conferences. Educational stipends or dedicated time for such activities may be provided.

## Ethics and Transparency
   - Transparency should be at the core of AI use in our organization. This includes citing the use of AI in creating documents or generating ideas.
   - Employees are expected to consider and address potential ethical concerns in their use of AI, such as issues of bias and exploitation.
   - Any use of AI must comply with existing privacy and confidentiality policies to ensure the protection of sensitive information.

## Definition and Use of AI-Written Content
   - AI-written content is defined as content significantly generated by AI, as defined by our three-part test.
   - AI-written content requires disclaimers and additional scrutiny due to its distinct nature.
   - AI-assisted content is differentiated as being the result of significant human modification of AI-generated suggestions. This is treated as human-authored content and continues with standard operations without necessitating special disclaimers.

## Protection Against Data Breaches and Stakeholder Communication
   - Employees are strictly prohibited from disclosing sensitive information to AI technologies, particularly cloud-based LLMs.
   - Any significant use of AI technologies, especially in the case of new projects or integration into existing processes, should be reported to managers or supervisors.

## Flexibility and Adaptability
   - This policy will be regularly reviewed and updated as necessary to adapt to the rapidly changing field of AI technology.

## Respect for Industry Professionals
   - AI integration is intended to facilitate and enhance the work of industry professionals, not to replace them. Ongoing training and resources will be provided to help employees adapt to and utilize AI in their work.
   - Employees are encouraged to develop and hone their human-centric skills, such as critical thinking, creativity, and interpersonal communication, which are complemented by AI.
   - Professionals are advised not to overly rely on AI for their work and to balance the use of AI tools with human skills and judgment.

## Responsiveness to Regulatory Landscape
   - Our organization will actively monitor the evolving regulatory environment around the use of AI and adapt our policies and practices as needed to ensure full compliance with local, state, federal, and international laws.
   - We will engage in an ongoing dialogue with regulators, industry groups, and peer organizations to stay informed about best practices and emerging issues in AI use.

## Evaluating and Mitigating AI Risks
   - We will conduct regular risk assessments of our AI use, taking into account potential threats to data security, privacy, and ethical standards.
   - The organization will establish a system of checks and balances to ensure that AI is being used responsibly and is not contributing to biases or other harm.
   - We will maintain a dedicated team or designate a person responsible for overseeing the ethical use of AI and addressing any issues that arise.

**Sample AI transparency label:**  
"The content of this email was generated with the help of an AI Large Language Model (LLM), and carefully reviewed by our team for accuracy and alignment with our campaign values."

# Three-Part Test for Defining AI-Written Content

This test is designed to distinguish between AI-written and AI-assisted content. Content can be categorized as AI-written if it meets the following criteria:

## Test 1: Source of Functionally Impactful Ideas
The origin of the core content or ideas is evaluated. If an AI tool primarily generated the ideas that drive the function of the message, the content should be considered AI-authored. On the other hand, if an AI tool was merely instrumental in refining or enhancing a human's original ideas without contributing new functionally impactful ideas, the content passes this test.

## Test 2: Degree and Impact of Human Input
This test evaluates the degree and impact of human input in crafting the key message, framing, or call-to-action. If a human substantively alters or contributes to these crucial elements, the content passes this test. Conversely, if an AI substantively alters or contributes to these crucial elements, the content should be considered AI-authored.

## Test 3: Degree of AI Autonomy and Narrative Control
This test assesses the degree of AI autonomy, especially regarding content distribution. In the context of a political fundraising campaign, each piece of communication - be it an email, text, or ad - forms a part of a larger narrative, like chapters in a book. Together, these chapters construct the complete campaign narrative, each contributing to the overall message. If an AI tool independently determines the sequence, timing, and recipient of these communications, it effectively contributes to shaping the narrative. Therefore, if the AI tool operates without substantial human influence in these decisions, the content should be considered AI-authored. If a human is making these key decisions, even based on AI-provided data, it passes the test.
