# AI Policy Guidelines

## Table of Contents

1. [Ethical Use of AI](#ethical-use-of-ai)
2. [Managing Risks Associated with AI Usage](#managing-risks-associated-with-ai-usage)
3. [Risk Evaluation and Mitigation](#risk-evaluation-and-mitigation)
4. [Oversight of AI Usage](#oversight-of-ai-usage)
5. [Dispute Resolution and AI Misuse](#dispute-resolution-and-ai-misuse)
6. [Data Shared with AI](#data-shared-with-ai)
7. [AI and Biases](#ai-and-biases)
8. [Data Shared with AI v2](#data-shared-with-ai-v2)
9. [AI and Biases v2](#ai-and-biases-v2)
10. [Use of Authorized AI Tools](#use-of-authorized-ai-tools)
11. [AI Training and Development](#ai-training-and-development)
12. [AI Experimentation](#ai-experimentation)
13. [Using Company-Provided AI Tools](#using-company-provided-ai-tools)
14. [Access Control to AI Tools](#access-control-to-ai-tools)
15. [Controlling AI Tool Installation & Data Access](#controlling-ai-tool-installation-&-data-access)
16. [Reporting New AI Uses](#reporting-new-ai-uses)
17. [Integrating AI into Workflow](#integrating-ai-into-workflow)
18. [AI Strategy for Organizations of Different Sizes](#ai-strategy-for-organizations-of-different-sizes)
19. [Integration with Other Organizational Policies](#integration-with-other-organizational-policies)
20. [Transparency](#transparency)
21. [Continuous Review and Update of Policies](#continuous-review-and-update-of-policies)
22. [Avoiding LLM Hallucinations](#avoiding-llm-hallucinations)
23. [Ensuring AI Accuracy](#ensuring-ai-accuracy)
24. [Accessibility and AI](#accessibility-and-ai)
25. [External AI Services](#external-ai-services)

---

## # Ethics and Risk Management

## 1. Ethical Use of AI

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to uphold ethical standards when using AI, including respecting fairness, transparency, and privacy. |
| Better | Provide employees with detailed ethical guidelines for AI use, including case studies and potential scenarios. |
| Best | Create an AI Ethics Committee to monitor AI use, provide ethical guidelines, handle dilemmas, and promote ongoing ethical education related to AI technologies. |

## 2. Managing Risks Associated with AI Usage

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to thoroughly review all AI outputs for accuracy, relevance, and potential issues, including any costs associated with unoptimized or excessive use. Promote a culture of consultation and peer review when employees are unsure. |
| Better | Require employees to conduct detailed checks on AI outputs for significant or high-risk tasks. Implement simple AI usage guidelines that help avoid common pitfalls such as excessive API calls, unchecked loops in AI-generated code, or exposure to sensitive information. |
| Best | Establish a comprehensive framework for AI risk management, including procedures for testing, verification, and validation of AI outputs in high-risk areas. Set up AI usage monitoring and real-time alert systems to track abnormal AI behavior. Regularly conduct AI risk training and audits. Develop a rapid response strategy to address any AI-related issues that arise. |

## 3. Risk Evaluation and Mitigation

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage team leaders to regularly evaluate the risks associated with AI use in their departments. |
| Better | Conduct organization-wide AI risk assessments on a semi-annual basis. |
| Best | Establish a dedicated AI Risk Assessment Team responsible for ongoing evaluation and mitigation of AI risks. Implement AI-specific risk management strategies based on their findings. |

## 4. Oversight of AI Usage

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage managers and team leads to have regular discussions with their teams about how they are using AI in their work, to understand and track usage patterns. |
| Better | Implement a process for employees to document and report their AI usage to their managers or a designated person, such as the AI Ethics Officer. This could be in the form of weekly or monthly reports. |
| Best | Use an AI usage monitoring system that can automatically track and report on AI usage across the organization, ensuring comprehensive oversight. This system should respect employee privacy by focusing on aggregate, anonymized data. |

## 5. Dispute Resolution and AI Misuse

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage a culture of open communication where employees feel safe to raise concerns about AI misuse. |
| Better | Implement a process for reporting and investigating potential AI misuse. |
| Best | Establish a formal dispute resolution procedure for handling issues arising from AI use. The process should be transparent, fair, and should outline potential penalties for intentional misuse. |

---

## # Data and Bias Management

## 6. Data Shared with AI

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to think carefully about the data they share with LLMs or other third-party tools. |
| Better | Provide explicit guidelines on types of data that should not be shared with AI, including private, sensitive, or confidential information. |
| Best | Prohibit employees from disclosing any sensitive data, and list specific examples of things employees may not want to feed into AI tools like ChatGPT. Also, offer regular training and audits to ensure compliance. |

## 7. AI and Biases

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to be aware of and account for potential AI biases in their work. |
| Better | Provide employees with training on how AI can reflect and perpetuate biases, and give them strategies for mitigating these biases. |
| Best | Create a dedicated team to monitor AI outputs for potential biases and develop an action plan for addressing any identified issues. This team should also work proactively to minimize biases in AI inputs and processes, guided by a strong commitment to fairness and equality. |

## 8. Data Shared with AI v2

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to think carefully about the data they share with AI, considering privacy and security implications. |
| Better | Provide explicit guidelines on types of data that should not be shared with AI, including private, sensitive, or confidential information. For example, data containing personally identifiable information (PII) like names, addresses, or social security numbers should not be shared without proper anonymization. |
| Best | Prohibit employees from disclosing any sensitive data, and list specific examples of things employees may not want to feed into AI tools like ChatGPT. Also, offer regular training and audits to ensure compliance. Data security measures, such as encryption and de-identification techniques, should be used to protect sensitive data. |

## 9. AI and Biases v2

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to be aware of potential AI biases, such as those based on gender, race, age, or socioeconomic status. |
| Better | Provide employees with training on how AI can reflect and perpetuate biases. For example, if an AI is trained on data that contains gender bias, it may make recommendations that unfairly favor one gender over another. |
| Best | Create a dedicated team to monitor AI outputs for potential biases and develop an action plan for addressing any identified issues. This team should work proactively to minimize biases in AI inputs and processes, guided by a strong commitment to fairness and equality. For example, they might regularly test AI systems with a diverse range of inputs to ensure fair treatment of all groups. |

## 10. Use of Authorized AI Tools

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to use authorized AI tools with known privacy measures in place. |
| Better | Require employees to use only specific, authorized LLMs with privacy measures in place, such as ChatGPT's private chat history & training. |
| Best | Implement a whitelist of AI tools that are approved for use, with clear instructions on how each should be used to ensure privacy and security. Require employees to use only tools on this whitelist for work-related tasks, and conduct regular reviews and updates of the list. |

---

## # AI Tools and Training

## 11. AI Training and Development

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to seek out training and development opportunities in AI technology. |
| Better | Provide regular in-house training sessions and resources for AI technology. |
| Best | Establish a comprehensive AI training and certification program for all employees. Require completion for anyone working directly with AI technologies. |

## 12. AI Experimentation

| Policy Level | Description |
|--------------|-------------|
| Good | Experiment with free AI tools such as ChatGPT, free image generation tools, and look at new AI features in your existing tech stack. Use tools like Canva and AppSheets. |
| Better | Experiment with ChatGPT+, Midjourney, freemium browser plugins like Compose.ai, and look at new AI features in your existing tech stack. Utilize integrations/connecting up (Zapier) and experiment with APIs (whisper). |
| Best | Experiment with OpenAI APIs and Github Co-pilot. Consider setting up experimental projects, like building a tech stack that includes an LLM on a cloud provider, or use transfer learning to make domain-specific bots (if you have enough training data). |

## 13. Using Company-Provided AI Tools

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to use company-provided AI accounts, such as a ChatGPT account, for any work-related AI tasks. Make it clear that these accounts are for business use only, and personal usage should be minimized or avoided entirely. |
| Better | Require employees to use company-provided AI accounts for all work-related AI tasks. Establish guidelines around what constitutes appropriate use of these accounts and provide regular training to ensure employees understand these guidelines. |
| Best | Establish a policy that all work-related AI tasks must be conducted using company-provided AI accounts. Implement monitoring and auditing mechanisms to review usage and enforce the policy. Offer regular training sessions and provide a channel for employees to ask questions or report potential misuse. |

## 14. Access Control to AI Tools

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to use only approved AI tools and discourage them from accessing unauthorized AI websites or services from their work devices. |
| Better | Implement a policy that only allows employees to use approved AI tools for work-related tasks. Regularly review and update the list of approved tools. |
| Best | Use network-level controls, such as firewalls or content filtering, to block access to unauthorized AI websites or services from work devices. Regularly review and update these controls to reflect changes in approved tools. Be transparent with employees about these controls and provide a clear rationale and guidelines for their use. |

## 15. Controlling AI Tool Installation & Data Access

| Policy Level | Description |
|--------------|-------------|
| Good | Implement a policy stating that all software installations, including AI extensions, must be approved by a manager or IT department. Encourage employees to check with their supervisor or IT before downloading any new software. |
| Better | Provide a list of approved software and extensions that employees are permitted to install and use. Require IT approval for any software not on this list. Use permissions settings in your organization's software to prevent unapproved installations. |
| Best | Implement a strict policy where only the IT department can install new software. Use centralized IT management tools to control software installations and updates on all company devices. Also, establish a whitelist of approved applications and blacklist unapproved or risky applications. Regularly educate employees on the risks of unauthorized software and the importance of data security. |

## 16. Reporting New AI Uses

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to share new AI uses with their manager or designated person/process. |
| Better | Employees must report all significant uses of AI to their manager or designated person/process. |
| Best | Employees must use the company's designated AI tracking system to document all significant uses of AI, including purpose, data inputs, and outcomes. |

## 17. Integrating AI into Workflow

| Policy Level | Description |
|--------------|-------------|
| Good | Explore tool libraries and freemium models. Mainly use tools and some experimentation with APIs. |
| Better | More on the side/experimentation with APIs. Mainly use tools, integrations / connecting up (Zapier). More thinking about how AI can fit into day-to-day workflows. |
| Best | Experimental projects that incorporate LLMs, such as involving WordPress integrations, etc. Be mindful of policies needed to protect you around it. |

## 18. AI Strategy for Organizations of Different Sizes

| Policy Level | Description |
|--------------|-------------|
| Good (Small Org) | Look at new AI features in your existing tech stack (enterprise level). Don’t build anything in-house yet. |
| Better (Large Org) | Speak to other digital leads in similar organizations and wait until more formalized guidance or tools are developed. Set up experimental projects, mindful of policies needed to protect around AI. |
| Best (Large Org with dedicated digital team) | Develop custom digital services with the integration of AI tools like GitHub Copilot and other LLMs. Experimental projects that incorporate LLMs with transfer learning to make domain-specific bots (if you have enough training data). |

## 19. Integration with Other Organizational Policies

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to consider how AI policies relate to other existing organizational policies. |
| Better | Conduct a formal review to ensure alignment of AI policies with other organizational policies such as HR, IT, and data governance. |
| Best | Integrate AI policies into the organization's overall policy framework, ensuring consistency and alignment across all areas. Regularly review and update these to avoid contradictions or conflicts. |

## 20. Transparency

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage the use of AI systems that provide some level of transparency in their decisions. |
| Better | Implement a policy for using explainable AI models where possible. |
| Best | Establish a commitment to transparency in AI applications, including the use of explainable AI models and clear communication about how AI decisions are made. |

## 21. Continuous Review and Update of Policies

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage regular team discussions to assess the relevance and effectiveness of AI policies. |
| Better | Conduct formal reviews of AI policies at defined intervals (e.g., annually). |
| Best | Establish a dedicated team or role for continuously monitoring advancements in AI, and updating AI policies to reflect changes in technology, regulations, and societal expectations. |

---

## # Special Topics

## 22. Avoiding LLM Hallucinations

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to be vigilant for potential LLM "hallucinations" or false statements, and cross-check all AI-generated information. |
| Better | Provide training to employees about common types of AI "hallucinations" and methods for identifying and mitigating them. |
| Best | Implement a robust system of checks and balances for AI outputs including peer reviews, automated fact-checking, and manual validation. Include specific steps to address and learn from any identified hallucinations. |

## 23. Ensuring AI Accuracy

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage employees to verify the accuracy of AI outputs, cross-referencing any factual claims with reliable sources. |
| Better | Require employees to review all products of AI for accuracy. This includes manually cross-verifying all assertions, assumptions, etc. |
| Best | Develop a rigorous verification system involving multiple employees and automated processes. This system should include feedback loops to improve AI accuracy over time. Provide regular accuracy reports to promote accountability and continual improvement. |

## 24. Accessibility and AI

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage the use of AI tools that promote accessibility. |
| Better | Implement a policy requiring the use of AI tools that meet accessibility standards. |
| Best | Establish a commitment to using AI to enhance accessibility. Implement training and guidelines for creating and using accessible AI systems. |

## 25. External AI Services

| Policy Level | Description |
|--------------|-------------|
| Good | Encourage due diligence when considering external AI services. |
| Better | Implement a policy detailing steps for vetting and using external AI services, including data transfer protocols. |
| Best | Establish a comprehensive policy for using external AI services, including robust due diligence processes, strict data transfer protocols, and regular audits. |
